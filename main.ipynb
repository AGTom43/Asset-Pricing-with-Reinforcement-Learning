{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  Last Price    Volume  SMAVG (15)      10_MA\n",
      "10   2023-03-08 18:00:00    0.499995  0.043372    0.074594  110.68384\n",
      "11   2023-03-08 18:30:00    0.521974  0.046837    0.076402  110.52084\n",
      "12   2023-03-08 19:00:00    0.527885  0.038593    0.075786  110.34875\n",
      "13   2023-03-08 19:30:00    0.505948  0.067524    0.078888  110.06875\n",
      "14   2023-03-08 20:00:00    0.492211  0.085734    0.084456  109.81575\n",
      "...                  ...         ...       ...         ...        ...\n",
      "1861 2023-10-02 15:00:00    0.755034  0.144825    0.184963  116.95750\n",
      "1862 2023-10-02 15:30:00    0.762818  0.113712    0.166506  116.69050\n",
      "1863 2023-10-02 16:00:00    0.764192  0.092697    0.157100  116.44500\n",
      "1864 2023-10-02 16:30:00    0.761445  0.078738    0.145187  116.21300\n",
      "1865 2023-10-02 17:00:00    0.771747  0.055809    0.135850  116.05450\n",
      "\n",
      "[1856 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "\n",
    "\n",
    "# Load data\n",
    "#C:\\Users\\rohit\\OneDrive\\Documents\\Asset-Pricing-with-Reinforcement-Learning\\XOM_30_minute_6_month_data.csv\n",
    "df = pd.read_csv('XOM_30_minute_6_month_data.csv', parse_dates=['Date'])\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Calculate the 10-period moving average\n",
    "# df['10_MA'] = df['Last Price'].rolling(window=10).mean()\n",
    "# df.to_csv('XOM_30_minute_6_month_data.csv', index=False)\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "df[['Last Price', 'Volume', 'SMAVG (15)']] = scaler.fit_transform(df[['Last Price', 'Volume', 'SMAVG (15)']])\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "print(train_df[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGTradingEnv(gymnasium.Env):\n",
    "\n",
    "  def __init__(self, df):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.df = df\n",
    "    self.current_step = 0\n",
    "    self.total_steps = 650 #len(df) - 1\n",
    "\n",
    "    # Negatives mean quantity to sell, 0 is hold, positives mean buy\n",
    "    self.action_space = spaces.Box(low=-1, high=1, shape=(1, ), dtype=np.float32)\n",
    "    # Observation space: normalized last price, normalized shares held, normalized cash balance\n",
    "    self.observation_space = spaces.Box(low=0, high=1, shape=(5,), dtype=np.float32)\n",
    "\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.current_step = 0\n",
    "    self.total_profit = 0\n",
    "    self.cash_balance = 10000\n",
    "    self.max_share_order = 50\n",
    "    self.shares_held = 0\n",
    "    self.portfolio_value = self.cash_balance\n",
    "    self.previous_portfolio_value = self.portfolio_value\n",
    "    # For plotting\n",
    "    self.portfolio_history = [np.array([self.portfolio_value], dtype=np.float32)]\n",
    "\n",
    "    return self.get_observation()\n",
    "\n",
    "  def get_observation(self):\n",
    "    current_price = self.df.loc[self.current_step, 'Last Price']\n",
    "    volume = self.df['Volume'].iloc[self.current_step]\n",
    "    MA_10 = self.df['10_MA'].iloc[self.current_step]\n",
    "    return np.array([float(current_price), float(self.shares_held), float(self.cash_balance), float(volume), float(MA_10)])\n",
    "\n",
    "  def take_action(self, num_shares):\n",
    "    current_price = self.df.loc[self.current_step, 'Last Price']\n",
    "    # Checks if we have enough cash to buy\n",
    "    print(\"num_shares: \", num_shares)\n",
    "    print(\"current_price: \", current_price)\n",
    "    if num_shares > 0 and self.cash_balance > (num_shares*current_price):\n",
    "      self.buy_stock(num_shares, current_price)\n",
    "    # Checks we have enough shares to sell\n",
    "    elif num_shares < 0 and self.shares_held > -num_shares:\n",
    "      self.sell_stock(-num_shares, current_price)\n",
    "    # Update the portfolio value\n",
    "    self.previous_portfolio_value = self.portfolio_value\n",
    "    self.portfolio_value = self.cash_balance + (self.shares_held * current_price)\n",
    "\n",
    "  def buy_stock(self, num_stocks, current_price):\n",
    "    print(\"buying\")\n",
    "    self.cash_balance -= (num_stocks * current_price)\n",
    "    self.shares_held += num_stocks\n",
    "\n",
    "  def sell_stock(self, num_stocks, current_price):\n",
    "    print(\"selling\")\n",
    "    self.cash_balance += (num_stocks * current_price)\n",
    "    self.shares_held -= num_stocks\n",
    "\n",
    "  # Action space is one number between -1 and 1.\n",
    "  def step(self, action):\n",
    "    print(\"Shares held: \", self.shares_held)\n",
    "    print(\"Cash balance: \", self.cash_balance)\n",
    "    print(\"Portfolio value: \", self.portfolio_value)\n",
    "    self.current_step += 1\n",
    "    self.take_action(action*self.max_share_order)\n",
    "    reward = self.calculate_reward()\n",
    "    terminated = (self.current_step >= self.total_steps)\n",
    "    observation = self.get_observation()\n",
    "    info = {'current_step': self.current_step, 'portfolio_value': self.portfolio_value}\n",
    "    self.portfolio_history.append(self.portfolio_value)\n",
    "    return observation, reward, terminated, info\n",
    "\n",
    "  def render(self, mode='human'):\n",
    "    if mode == 'human':\n",
    "      print(f\"Step: {self.current_step}, Portfolio Value: {self.portfolio_value}\")\n",
    "\n",
    "  # The reward is the change in portfolio value the next time_step\n",
    "  def calculate_reward(self):\n",
    "    reward = self.portfolio_value - self.previous_portfolio_value\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor & Critic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Current state\n",
    "# Output: Action to be taken\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=128):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "# Input: Current State & Actor's action\n",
    "# Output: Expected value of state-action pair\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1_state = nn.Linear(state_dim, 64)\n",
    "        self.fc2_state = nn.Linear(64, 64)\n",
    "        self.fc2_action = nn.Linear(action_dim, 64)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x_state = F.relu(self.fc1_state(state))\n",
    "        x_state = F.relu(self.fc2_state(x_state))\n",
    "\n",
    "        x_action = F.relu(self.fc2_action(action))\n",
    "\n",
    "        x = torch.cat((x_state, x_action), dim=0)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shares held:  0\n",
      "Cash balance:  10000\n",
      "Portfolio value:  10000\n",
      "num_shares:  [-49.790283]\n",
      "current_price:  0.5966080275460408\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got numpy.float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 130\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Execute action 𝐴, observe reward 𝑅 and next-state 𝑆′\u001b[39;00m\n\u001b[1;32m    128\u001b[0m new_state, reward, terminated, info \u001b[38;5;241m=\u001b[39m DDPG_agent\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m--> 130\u001b[0m \u001b[43mDDPG_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Update state\u001b[39;00m\n\u001b[1;32m    133\u001b[0m state \u001b[38;5;241m=\u001b[39m new_state\n",
      "Cell \u001b[0;32mIn[119], line 101\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, state, action, reward, new_state, terminated)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, action, reward, new_state, terminated):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_transition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     minibatch_sampled_from_D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_minibatch()\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# For each transition (𝑆𝑗,𝐴𝑗,𝑅𝑗,𝑆′𝑗) in minibatch sampled from 𝐷:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[119], line 54\u001b[0m, in \u001b[0;36mDDPG.store_transition\u001b[0;34m(self, state, action, reward, new_state)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore_transition\u001b[39m(\u001b[38;5;28mself\u001b[39m, state, action, reward, new_state):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Store transition (𝑆,𝐴,𝑅,𝑆′) in 𝐷\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# transition = (state, action, reward, new_state)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     transition \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mFloatTensor(state), torch\u001b[38;5;241m.\u001b[39mFloatTensor(action), \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mFloatTensor(new_state))\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_memory\u001b[38;5;241m.\u001b[39mappend(transition)\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got numpy.float64)"
     ]
    }
   ],
   "source": [
    "# Because DDPG is an off-policy actor-critic policy-gradient algorithm, this means that the critic\n",
    "# evaluates the actor, but because they are off-policy, the agents act according to their own\n",
    "# policy but learn according to the target policy.\n",
    "\n",
    "class DDPG:\n",
    "    def __init__(self, df):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Initialise environment:\n",
    "        self.env = DDPGTradingEnv(df)\n",
    "        # Pseudocode line 1:\n",
    "        # Initialize replay memory 𝐷 to capacity 𝑁\n",
    "        self.N = 1000\n",
    "        self.replay_memory = []\n",
    "        # replay_memory = deque(maxlen=N)\n",
    "        # Initialise minibatch size\n",
    "        self.minibatch_size = 50\n",
    "        # Pseudocode line 2 & 3:\n",
    "        # Initialize actor network 𝜋̂ 1 with parameters 𝒘1 arbitrarily\n",
    "        # Initialize target actor network 𝜋̂ 2 with parameters 𝒘2=𝒘1\n",
    "        self.state_dim = 5\n",
    "        self.action_dim = 1\n",
    "        self.actor_model = Actor(self.state_dim, self.action_dim)\n",
    "        self.target_actor_model = Actor(self.state_dim, self.action_dim)\n",
    "        # Pseudocode line 4 & 5:\n",
    "        # Initialize critic network 𝑞̂ 1 with parameters 𝜽1 arbitrarily\n",
    "        # Initialize target critic network 𝑞̂ 2 with parameters 𝜽2=𝜽1\n",
    "        self.critic_model = Critic(self.state_dim, self.action_dim)\n",
    "        self.target_critic_model = Critic(self.state_dim, self.action_dim)\n",
    "\n",
    "        # Initialise random process ϵ for action exploration\n",
    "        self.epsilon = 0.1\n",
    "        # Pseudocode line 6: Algorithm parameters: target network learning rate 𝛽>0\n",
    "        self.beta = 0.005\n",
    "        # Gamma is the discount factor (importance of future rewards)\n",
    "        self.gamma = 0.9\n",
    "        # This is for the gradient descent\n",
    "        self.lr = 0.005\n",
    "        # Optimizers\n",
    "        self.optimizer_critic = optim.Adam(self.critic_model.parameters(), lr=self.lr)\n",
    "        self.optimizer_actor = optim.Adam(self.actor_model.parameters(), lr=self.lr)\n",
    "\n",
    "    # policy\n",
    "    def select_action(self, state):\n",
    "        # Select action 𝐴←𝜋̂ 1(𝑆,𝒘1)+\n",
    "        action = self.actor_model(torch.FloatTensor(state).to(self.device))\n",
    "        action = action.detach().to('cpu').numpy()\n",
    "        # Add exploration noise (optional). Adds dampened value within action space\n",
    "        action += self.epsilon * np.random.randn(self.action_dim)\n",
    "        return action\n",
    "    \n",
    "    def store_transition(self, state, action, reward, new_state):\n",
    "        # Store transition (𝑆,𝐴,𝑅,𝑆′) in 𝐷\n",
    "        # transition = (state, action, reward, new_state)\n",
    "        transition = (torch.FloatTensor(state), torch.FloatTensor(action), torch.FloatTensor(reward), torch.FloatTensor(new_state))\n",
    "        self.replay_memory.append(transition)\n",
    "    \n",
    "    # Allows you to perform updates more frequently & helps with regularisation\n",
    "    def sample_minibatch(self):\n",
    "        if len(self.replay_memory) <= self.minibatch_size:\n",
    "            return self.replay_memory\n",
    "        else:\n",
    "            return random.sample(self.replay_memory, self.minibatch_size)\n",
    "        \n",
    "    def update_critic(self, state, action, reward, new_state):\n",
    "        # Makes sure state and action are on same device\n",
    "        state = state.to(self.device)\n",
    "        action = action.to(self.device)\n",
    "        new_state_tensor = torch.FloatTensor(new_state).to(self.device)\n",
    "\n",
    "        # 𝜋̂ 2(𝑆′𝑗,𝒘2)\n",
    "        target_actor_output = self.target_actor_model(new_state_tensor)\n",
    "        # y is the TD target value (improved Q-value) for the critic (calculated using actor)\n",
    "        y = reward + self.gamma * self.target_critic_model(new_state_tensor, target_actor_output)\n",
    "        \n",
    "        # Perform gradient descent step ∇𝜽1(𝑦−𝑞̂ 1(𝑆𝑗,𝐴𝑗,𝜽1))2 for critic (critic learning from target critic)\n",
    "        critic_output = self.critic_model(state, action)\n",
    "        # critic_loss = F.mse_loss(critic_output, y)\n",
    "        # y.detach removes tensor\n",
    "        critic_loss = nn.MSELoss().to(self.device)(critic_output, y.detach())\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "    \n",
    "    def update_actor(self, state):\n",
    "        # Perform gradient ascent step ∇𝑤1𝐸[𝑞̂ 1(𝑆𝑗,𝜋̂ 1(𝑆𝑗,𝒘1),𝜽1)] for actor (actor learning from critic)\n",
    "        actor_output = self.actor_model(state)\n",
    "        actor_loss = -torch.mean(self.critic_model(state, actor_output))\n",
    "        self.optimizer_actor.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.optimizer_actor.step()\n",
    "\n",
    "    def update_target_network_parameters(self):\n",
    "        # Update target actor network parameters 𝒘2←𝛽𝒘1+(1−𝛽)𝒘2\n",
    "        for target_param, param in zip(self.target_actor_model.parameters(), self.actor_model.parameters()):\n",
    "            target_param.data.copy_(self.beta * param.data + (1 - self.beta) * target_param.data)    \n",
    "        # Update target critic network parameters 𝜽2←𝛽𝜽1+(1−𝛽)𝜽2\n",
    "        for target_param, param in zip(self.target_critic_model.parameters(), self.critic_model.parameters()):\n",
    "            target_param.data.copy_(self.beta * param.data + (1 - self.beta) * target_param.data)\n",
    "\n",
    "    def learn(self, state, action, reward, new_state, terminated):\n",
    "        self.store_transition(state, action, reward, new_state)\n",
    "        minibatch_sampled_from_D = self.sample_minibatch()\n",
    "        # For each transition (𝑆𝑗,𝐴𝑗,𝑅𝑗,𝑆′𝑗) in minibatch sampled from 𝐷:\n",
    "        for transition in minibatch_sampled_from_D:\n",
    "            # 𝑦←𝑅𝑗+𝛾𝑞̂ 2(𝑆′𝑗,𝜋̂ 2(𝑆′𝑗,𝒘2),𝜽2)\n",
    "            state, action, reward, new_state = transition\n",
    "            self.update_critic(state, action, reward, new_state)\n",
    "            self.update_actor(state)\n",
    "        self.update_target_network_parameters()\n",
    "\n",
    "\n",
    "# Loop for each episode:\n",
    "num_episodes = 1\n",
    "DDPG_agent = DDPG(df)\n",
    "\n",
    "for i in range(num_episodes):\n",
    "\n",
    "    # Initialise S\n",
    "    state = DDPG_agent.env.reset()\n",
    "\n",
    "    # Loop for each step of episode (each time step in df)\n",
    "    terminated = False\n",
    "    while not terminated:\n",
    "        \n",
    "        action = DDPG_agent.select_action(state)\n",
    "        \n",
    "        # Execute action 𝐴, observe reward 𝑅 and next-state 𝑆′\n",
    "        new_state, reward, terminated, info = DDPG_agent.env.step(action)\n",
    "        \n",
    "        DDPG_agent.learn(state, action, reward, new_state, terminated)\n",
    "\n",
    "        # Update state\n",
    "        state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([10000.], dtype=float32), 10000.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABCMElEQVR4nO3df3zP9f7/8ft72Huz2S+yX2YNNT+OKMIkKsuIECVS4ciPDkdSkgqhIpRfJ6nOOQjlV/mRnCREZVQ0vy1KETbCNj9ntuf3D9+9Pt5t9Hprs/e4XS+X9+Wc9/P1fD1fj+fL8r57vZ+v1xzGGCMAAABclldRFwAAAFAcEJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCagOvId999p4YNG8rPz08Oh0NJSUm2950+fbocDod++eUXq+2uu+7SXXfdVeB1ulPP999/XyTHx1/zyy+/yOFwaPr06UVdCmAboQm4CnI/4HNfPj4+uvnmm9W3b1+lpqYW6LFee+01LVq0KE97VlaWHnroIR07dkzjx4/XzJkzFR0dXaDHLigLFy5UixYtVK5cOXl7eysiIkIdOnTQqlWrirq0InH06FENHDhQsbGx8vHxUUhIiBISErR06dKiLs3Fyy+/7PJzfqlXUQVt4K8qWdQFANeTESNGKCYmRmfPntXXX3+tt99+W8uWLdO2bdtUunTpAjnGa6+9pgcffFBt27Z1af/pp5/066+/6r333tMTTzxRIMf6/PPPC2ScXMYY/f3vf9f06dN16623asCAAQoLC9OhQ4e0cOFCNW3aVN98840aNmxYoMf1ZMnJyWratKmOHDmibt26qW7dukpLS9Ps2bN1//3369lnn9XYsWOLukxJUrt27VSlShXr/cmTJ/Xkk0/qgQceULt27az20NBQRUdH68yZMypVqlRRlApcEUITcBW1aNFCdevWlSQ98cQTKlu2rN58800tXrxYnTp1uuJxjTE6e/asfH19L9nn8OHDkqSgoKArPs4feXt7F9hYkvTGG29o+vTp6t+/v9588005HA5r24svvqiZM2eqZMnr56+trKwsPfjggzp+/LjWrl2r+vXrW9uefvppde7cWePGjVPdunX18MMPX7W6zp8/r5ycnDx//rfccotuueUW6/3vv/+uJ598UrfccoseffTRPOP4+PgUeq1AQeLrOaAI3XPPPZKkvXv3SrrwYTRy5EhVrlxZTqdTN954o1544QVlZma67HfjjTeqVatWWr58uerWrStfX1+98847cjgcOnXqlGbMmGF9FdK1a1d17dpVTZo0kSQ99NBDeb4iWbVqle688075+fkpKChIbdq00c6dO/+0/vzWNB0+fFjdu3dXaGiofHx8VKtWLc2YMeNPxzpz5oxGjRqlqlWraty4cS6BKddjjz2mevXqubRlZmZqwIABuuGGG+Tn56cHHnhAR44ccemzePFitWzZUhEREXI6napcubJGjhyp7OzsPPP529/+ph07dujuu+9W6dKlFRkZqTFjxuSp5ddff1Xr1q3l5+en8uXL6+mnn9by5cvlcDj05ZdfuvTdsGGDmjdvrsDAQJUuXVpNmjTRN99886fn5KOPPtK2bdv0/PPPuwQmSSpRooTeeecdBQUF6eWXX5YkpaamqmTJkho+fHiesZKTk+VwOPSvf/3LaktLS1P//v0VFRUlp9OpKlWq6PXXX1dOTo7VJ3ft0bhx4zRhwgTrZ3PHjh1/Wv/l5LemqWvXrvL399e+ffvUqlUr+fv7KzIyUm+99ZYkaevWrbrnnnvk5+en6OhoffDBB3nGtTMn4EpdP/9kAzzQTz/9JEkqW7aspAtXn2bMmKEHH3xQzzzzjDZs2KBRo0Zp586dWrhwocu+ycnJ6tSpk3r16qUePXooNjZWM2fO1BNPPKF69eqpZ8+ekqTKlStLkiIjI/Xaa6+pX79+uv322xUaGipJ+uKLL9SiRQtVqlRJL7/8ss6cOaPJkyfrjjvu0KZNm3TjjTfans+ZM2d01113ac+ePerbt69iYmI0f/58de3aVWlpaXrqqacuue/XX3+tY8eOqX///ipRooTtY/7zn/9UcHCwhg0bpl9++UUTJkxQ3759NXfuXKvP9OnT5e/vrwEDBsjf31+rVq3S0KFDlZGRkeerrePHj6t58+Zq166dOnTooAULFmjQoEGqWbOmWrRoIUk6deqU7rnnHh06dEhPPfWUwsLC9MEHH2j16tV56lu1apVatGihOnXqaNiwYfLy8tK0adN0zz336KuvvsoTAi/2ySefSJIef/zxfLcHBgaqTZs2mjFjhvbs2aMqVaqoSZMmmjdvnoYNG+bSd+7cuSpRooQeeughSdLp06fVpEkTHThwQL169VLFihW1bt06DR48WIcOHdKECRNc9p82bZrOnj2rnj17yul0KiQk5JJ1/xXZ2dlq0aKFGjdurDFjxmj27Nnq27ev/Pz89OKLL6pz585q166dpk6dqscff1xxcXGKiYm5ojkBbjMACt20adOMJPPFF1+YI0eOmP3795s5c+aYsmXLGl9fX/Pbb7+ZpKQkI8k88cQTLvs+++yzRpJZtWqV1RYdHW0kmc8++yzPsfz8/EyXLl3ytK9evdpIMvPnz3dpr127tilfvrw5evSo1bZ582bj5eVlHn/88Txz2Lt3r9XWpEkT06RJE+v9hAkTjCQza9Ysq+3cuXMmLi7O+Pv7m4yMjEueo4kTJxpJZuHChZfsc7HceuLj401OTo7V/vTTT5sSJUqYtLQ0q+306dN59u/Vq5cpXbq0OXv2rMt8JJn333/fasvMzDRhYWGmffv2Vtsbb7xhJJlFixZZbWfOnDFVq1Y1kszq1auNMcbk5OSYm266ySQkJLjUePr0aRMTE2Puvffey86xdu3aJjAw8LJ93nzzTSPJLFmyxBhjzDvvvGMkma1bt7r0q169urnnnnus9yNHjjR+fn7mxx9/dOn3/PPPmxIlSph9+/YZY4zZu3evkWQCAgLM4cOHL1vLHx05csRIMsOGDcuzLXfcadOmWW1dunQxksxrr71mtR0/ftz4+voah8Nh5syZY7Xv2rUrz9h25wRcKb6eA66i+Ph43XDDDYqKilLHjh3l7++vhQsXKjIyUsuWLZMkDRgwwGWfZ555RpL06aefurTHxMQoISHhL9Vz6NAhJSUlqWvXri5XDm655Rbde++9Vk12LVu2TGFhYS7rs0qVKqV+/frp5MmTWrNmzSX3zcjIkCSVKVPGrWP27NnT5au8O++8U9nZ2fr111+ttovXep04cUK///677rzzTp0+fVq7du1yGc/f399l/Y23t7fq1aunn3/+2Wr77LPPFBkZqdatW1ttPj4+6tGjh8tYSUlJ2r17tx555BEdPXpUv//+u37//XedOnVKTZs21dq1ay/7tdGJEyf+9Hzkbs89f+3atVPJkiVdrrRt27ZNO3bscFn3NH/+fN15550KDg626vr9998VHx+v7OxsrV271uU47du31w033HDZWgrKxTcqBAUFKTY2Vn5+furQoYPVHhsbq6CgIJc/F3fnBLiLr+eAq+itt97SzTffrJIlSyo0NFSxsbHy8rrwb5dff/1VXl5eLncfSVJYWJiCgoJcQoAk6yuJvyJ3zNjY2DzbqlWrpuXLl+vUqVPy8/OzPd5NN91kzenisS4+Xn4CAgIkXQgK7qhYsaLL++DgYEkXvmbLtX37dr300ktatWqVFS5ypaenu7yvUKFCnvVUwcHB2rJli/X+119/VeXKlfP0++Of3e7duyVJXbp0uWT96enpVs1/VKZMGf3++++X3Ff6v/OVG57KlSunpk2bat68eRo5cqSkC1/NlSxZ0uUOtt27d2vLli2XDEK5Nw7kKoifNzt8fHzy1BQYGJjvn0tgYKDLn7O7cwLcRWgCrqJ69epZd89dSn4LoPNzuTvliqOqVatKurDY94+PS7icS61/MsZIurAwuEmTJgoICNCIESNUuXJl+fj4aNOmTRo0aFCeKz1/Np47csceO3asateunW8ff3//S+5frVo1JSUlad++fXnCYa7cMFe9enWrrWPHjurWrZuSkpJUu3ZtzZs3T02bNlW5cuVcarv33nv13HPP5TvuzTff7PL+av28Xer82/lzcXdOgLsITYCHiI6OVk5Ojnbv3m1dmZEu3BGVlpZm+0GUdkNX7jGlC4vK/2jXrl0qV66c7atMueNt2bJFOTk5Llebcr8Cu9wcGjVqpODgYH344Yd64YUX3FoMfjlffvmljh49qo8//liNGze22nPvWLwS0dHR2rFjh4wxLud7z549Lv1yF+EHBAQoPj7e7eO0atVKH374od5//3299NJLebZnZGRo8eLFqlq1qstVrrZt26pXr17WV3Q//vijBg8enKe2kydPXlFdnupanBM8C2uaAA9x3333SVKeO3zefPNNSVLLli1tjePn56e0tDRbfcPDw1W7dm3NmDHDZZ9t27bp888/t2qy67777lNKSorLeprz589r8uTJ8vf3tx57kJ/SpUtr0KBB2rlzpwYNGpTvlZ1Zs2bp22+/daum3PB18Xjnzp3TlClT3BrnYgkJCTpw4ICWLFlitZ09e1bvvfeeS786deqocuXKGjdunE6ePJlnnD8+GuGPHnzwQVWvXl2jR4/O8+ticnJy9OSTT+r48eN57pQLCgpSQkKC5s2bpzlz5sjb2zvP1bsOHTooMTFRy5cvz3PctLQ0nT9//rK1eaJrcU7wLFxpAjxErVq11KVLF7377rvWV0rffvutZsyYobZt2+ruu++2NU6dOnX0xRdf6M0331RERIRiYmLyPOPnYmPHjlWLFi0UFxen7t27W48cCAwMtJ7/Y1fPnj31zjvvqGvXrtq4caNuvPFGLViwQN98840mTJjwp4uaBw4cqO3bt+uNN97Q6tWr9eCDDyosLEwpKSlatGiRvv32W61bt86tmho2bKjg4GB16dJF/fr1k8Ph0MyZM6/o67ZcvXr10r/+9S916tRJTz31lMLDwzV79mzrYY25V5+8vLz073//Wy1atFCNGjXUrVs3RUZG6sCBA1q9erUCAgKsxwrkx9vbWwsWLFDTpk3VqFEjlyeCf/DBB9q0aZOeeeYZdezYMc++Dz/8sB599FFNmTJFCQkJeR5qOnDgQC1ZskStWrVS165dVadOHZ06dUpbt27VggUL9Msvv7h8nVccXItzgocpwjv3gOtG7u3x33333WX7ZWVlmeHDh5uYmBhTqlQpExUVZQYPHuxyW7wxFx450LJly3zH2LVrl2ncuLHx9fU1kqzHD1zqkQPGGPPFF1+YO+64w/j6+pqAgABz//33mx07duQ7h8s9csAYY1JTU023bt1MuXLljLe3t6lZs6bLbeV2LFiwwDRr1syEhISYkiVLmvDwcPPwww+bL7/8Mk89fzynufPMve3fGGO++eYb06BBA+Pr62siIiLMc889Z5YvX56nX5MmTUyNGjXy1NOlSxcTHR3t0vbzzz+bli1bGl9fX3PDDTeYZ555xnz00UdGklm/fr1L3x9++MG0a9fOlC1b1jidThMdHW06dOhgVq5caet8HD582AwYMMBUqVLFOJ1OExQUZOLj463HDOQnIyPD+hm4+BEQFztx4oQZPHiwqVKlivH29jblypUzDRs2NOPGjTPnzp0zxvzfowHGjh1rq9aLXckjB/z8/PL0vdSfS37/HdiZE3ClHMb8hX9uAQAsEyZM0NNPP63ffvtNkZGRRV0OgAJGaAKAK3DmzBmXO8rOnj2rW2+9VdnZ2frxxx+LsDIAhYU1TQBwBdq1a6eKFSuqdu3aSk9P16xZs7Rr1y7Nnj27qEsDUEgITQBwBRISEvTvf/9bs2fPVnZ2tqpXr645c+a4PHUbwLWFr+cAAABs4DlNAAAANhCaAAAAbGBNUwHJycnRwYMHVaZMGbd+jQUAACg6xhidOHFCEREReX7Z+B8RmgrIwYMHFRUVVdRlAACAK7B//35VqFDhsn0ITQUk99dD7N+/XwEBAUVcDQAAsCMjI0NRUVF/+mueJEJTgcn9Si4gIIDQBABAMWNnaQ0LwQEAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsKFIQ9PatWt1//33KyIiQg6HQ4sWLXLZbozR0KFDFR4eLl9fX8XHx2v37t35jpWZmanatWvL4XAoKSnJZduWLVt05513ysfHR1FRURozZkye/efPn6+qVavKx8dHNWvW1LJlywpqmgAA4BpQpKHp1KlTqlWrlt566618t48ZM0aTJk3S1KlTtWHDBvn5+SkhIUFnz57N0/e5555TREREnvaMjAw1a9ZM0dHR2rhxo8aOHauXX35Z7777rtVn3bp16tSpk7p3764ffvhBbdu2Vdu2bbVt27aCmywAACjejIeQZBYuXGi9z8nJMWFhYWbs2LFWW1pamnE6nebDDz902XfZsmWmatWqZvv27UaS+eGHH6xtU6ZMMcHBwSYzM9NqGzRokImNjbXed+jQwbRs2dJlzPr165tevXrZrj89Pd1IMunp6bb3AQAARcudz2+PXdO0d+9epaSkKD4+3moLDAxU/fr1lZiYaLWlpqaqR48emjlzpkqXLp1nnMTERDVu3Fje3t5WW0JCgpKTk3X8+HGrz8XHye1z8XEAAMD1zWNDU0pKiiQpNDTUpT00NNTaZoxR165d1bt3b9WtW/eS4+Q3xsXHuFSf3O35yczMVEZGhssLAABcuzw2NNkxefJknThxQoMHD77qxx41apQCAwOtV1RU1FWvAQAAXD0eG5rCwsIkXfj67WKpqanWtlWrVikxMVFOp1MlS5ZUlSpVJEl169ZVly5drHHyG+PiY1yqT+72/AwePFjp6enWa//+/Vc6VQAAUAx4bGiKiYlRWFiYVq5cabVlZGRow4YNiouLkyRNmjRJmzdvVlJSkpKSkqzHBMydO1evvvqqJCkuLk5r165VVlaWNc6KFSsUGxur4OBgq8/Fx8ntk3uc/DidTgUEBLi8AADAtatkUR785MmT2rNnj/V+7969SkpKUkhIiCpWrKj+/fvrlVde0U033aSYmBgNGTJEERERatu2rSSpYsWKLuP5+/tLkipXrqwKFSpIkh555BENHz5c3bt316BBg7Rt2zZNnDhR48ePt/Z76qmn1KRJE73xxhtq2bKl5syZo++//97lsQQAAOA6V/g3813a6tWrjaQ8ry5duhhjLjx2YMiQISY0NNQ4nU7TtGlTk5ycfMnx9u7dm+eRA8YYs3nzZtOoUSPjdDpNZGSkGT16dJ59582bZ26++Wbj7e1tatSoYT799FO35sIjBwAAKH7c+fx2GGNM0UW2a0dGRoYCAwOVnp7OV3UAABQT7nx+e+yaJgAAAE9CaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsKNLQtHbtWt1///2KiIiQw+HQokWLXLYbYzR06FCFh4fL19dX8fHx2r17t7X9l19+Uffu3RUTEyNfX19VrlxZw4YN07lz51zG2bJli+688075+PgoKipKY8aMyVPL/PnzVbVqVfn4+KhmzZpatmxZocwZAAAUT0Uamk6dOqVatWrprbfeynf7mDFjNGnSJE2dOlUbNmyQn5+fEhISdPbsWUnSrl27lJOTo3feeUfbt2/X+PHjNXXqVL3wwgvWGBkZGWrWrJmio6O1ceNGjR07Vi+//LLeffddq8+6devUqVMnde/eXT/88IPatm2rtm3batu2bYV7AgAAQLHhMMaYoi5CkhwOhxYuXKi2bdtKunCVKSIiQs8884yeffZZSVJ6erpCQ0M1ffp0dezYMd9xxo4dq7fffls///yzJOntt9/Wiy++qJSUFHl7e0uSnn/+eS1atEi7du2SJD388MM6deqUli5dao3ToEED1a5dW1OnTrVVf0ZGhgIDA5Wenq6AgIArOgcAAODqcufz22PXNO3du1cpKSmKj4+32gIDA1W/fn0lJiZecr/09HSFhIRY7xMTE9W4cWMrMElSQkKCkpOTdfz4cavPxcfJ7XO54wAAgOuLx4amlJQUSVJoaKhLe2hoqLXtj/bs2aPJkyerV69eLuPkN8bFx7hUn0sdR5IyMzOVkZHh8gIAANcujw1N7jpw4ICaN2+uhx56SD169Cj0440aNUqBgYHWKyoqqtCPCQAAio7HhqawsDBJUmpqqkt7amqqtS3XwYMHdffdd6thw4YuC7xzx8lvjIuPcak+fzzOxQYPHqz09HTrtX//fjdmBwAAihuPDU0xMTEKCwvTypUrrbaMjAxt2LBBcXFxVtuBAwd01113qU6dOpo2bZq8vFynFBcXp7Vr1yorK8tqW7FihWJjYxUcHGz1ufg4uX0uPs4fOZ1OBQQEuLwAAMC1q0hD08mTJ5WUlKSkpCRJFxZ/JyUlad++fXI4HOrfv79eeeUVLVmyRFu3btXjjz+uiIgI6w673MBUsWJFjRs3TkeOHFFKSorLWqRHHnlE3t7e6t69u7Zv3665c+dq4sSJGjBggNXnqaee0meffaY33nhDu3bt0ssvv6zvv/9effv2vZqnAwAAeDJThFavXm0k5Xl16dLFGGNMTk6OGTJkiAkNDTVOp9M0bdrUJCcnW/tPmzYt3/3/OK3NmzebRo0aGafTaSIjI83o0aPz1DJv3jxz8803G29vb1OjRg3z6aefujWX9PR0I8mkp6e7fyIAAECRcOfz22Oe01Tc8ZwmAACKn2viOU0AAACehNAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA1/KTSdPXu2oOoAAADwaG6HppycHI0cOVKRkZHy9/fXzz//LEkaMmSI/vOf/xR4gQAAAJ7A7dD0yiuvaPr06RozZoy8vb2t9r/97W/697//XaDFAQAAeAq3Q9P777+vd999V507d1aJEiWs9lq1amnXrl0FWhwAAICncDs0HThwQFWqVMnTnpOTo6ysrAIpCgAAwNO4HZqqV6+ur776Kk/7ggULdOuttxZIUQAAAJ6mpLs7DB06VF26dNGBAweUk5Ojjz/+WMnJyXr//fe1dOnSwqgRAACgyLl9palNmzb65JNP9MUXX8jPz09Dhw7Vzp079cknn+jee+8tjBoBAACKnMMYY4q6iGtBRkaGAgMDlZ6eroCAgKIuBwAA2ODO5zdPBAcAALDB7TVNXl5ecjgcl9yenZ39lwoCAADwRG6HpoULF7q8z8rK0g8//KAZM2Zo+PDhBVYYAACAJymwNU0ffPCB5s6dq8WLFxfEcMUOa5oAACh+imRNU4MGDbRy5cqCGg4AAMCjFEhoOnPmjCZNmqTIyMiCGA4AAMDjuL2mKTg42GUhuDFGJ06cUOnSpTVr1qwCLQ4AAMBTuB2axo8f7xKavLy8dMMNN6h+/foKDg4u0OIAAAA8hduhqWvXroVQBgAAgGezFZq2bNlie8BbbrnliosBAADwVLZCU+3ateVwOPRnTydwOBw83BIAAFyTbIWmvXv3FnYdAAAAHs1WaIqOji7sOgAAADya2wvBc+3YsUP79u3TuXPnXNpbt279l4sCAADwNG6Hpp9//lkPPPCAtm7d6rLOKfcxBKxpAgAA1yK3nwj+1FNPKSYmRocPH1bp0qW1fft2rV27VnXr1tWXX35ZCCUCAAAUPbevNCUmJmrVqlUqV66cvLy85OXlpUaNGmnUqFHq16+ffvjhh8KoEwAAoEi5faUpOztbZcqUkSSVK1dOBw8elHRhsXhycnLBVgcAAOAh3L7S9Le//U2bN29WTEyM6tevrzFjxsjb21vvvvuuKlWqVBg1AgAAFDm3Q9NLL72kU6dOSZJGjBihVq1a6c4771TZsmU1d+7cAi8QAADAEzjMnz3m24Zjx44pODjY5Rf5Xm8yMjIUGBio9PR0BQQEFHU5AADABnc+v91e0zRr1izrSlOukJCQ6zowAQCAa5/boenpp59WaGioHnnkES1btoznMgEAgOuC26Hp0KFDmjNnjhwOhzp06KDw8HD16dNH69atK4z6AAAAPMJfWtN0+vRpLVy4UB988IG++OILVahQQT/99FNB1ldssKYJAIDix53P7yv+3XOSVLp0aSUkJOj48eP69ddftXPnzr8yHAAAgMdy++s56cIVptmzZ+u+++5TZGSkJkyYoAceeEDbt28v6PoAAAA8gttXmjp27KilS5eqdOnS6tChg4YMGaK4uLjCqA0AAMBjuB2aSpQooXnz5ikhIUElSpQojJoAAAA8jtuhafbs2YVRBwAAgEe7ojVNAAAA1xtCEwAAgA2EJgAAABsITQAAADZc0cMts7OztWjRIuthljVq1FDr1q25mw4AAFyz3A5Ne/bsUcuWLfXbb78pNjZWkjRq1ChFRUXp008/VeXKlQu8SAAAgKLm9tdz/fr1U6VKlbR//35t2rRJmzZt0r59+xQTE6N+/fq5NdbatWt1//33KyIiQg6HQ4sWLXLZbozR0KFDFR4eLl9fX8XHx2v37t0ufY4dO6bOnTsrICBAQUFB6t69u06ePOnSZ8uWLbrzzjvl4+OjqKgojRkzJk8t8+fPV9WqVeXj46OaNWtq2bJlbs0FAABc29wOTWvWrNGYMWMUEhJitZUtW1ajR4/WmjVr3Brr1KlTqlWrlt566618t48ZM0aTJk3S1KlTtWHDBvn5+SkhIUFnz561+nTu3Fnbt2/XihUrtHTpUq1du1Y9e/a0tmdkZKhZs2aKjo7Wxo0bNXbsWL388st69913rT7r1q1Tp06d1L17d/3www9q27at2rZtq23btrk1HwAAcA0zbgoODjbffPNNnvavv/7aBAcHuzucRZJZuHCh9T4nJ8eEhYWZsWPHWm1paWnG6XSaDz/80BhjzI4dO4wk891331l9/ve//xmHw2EOHDhgjDFmypQpJjg42GRmZlp9Bg0aZGJjY633HTp0MC1btnSpp379+qZXr162609PTzeSTHp6uu19AABA0XLn89vtK02tWrVSz549tWHDBhljZIzR+vXr1bt3b7Vu3brAwtzevXuVkpKi+Ph4qy0wMFD169dXYmKiJCkxMVFBQUGqW7eu1Sc+Pl5eXl7asGGD1adx48by9va2+iQkJCg5OVnHjx+3+lx8nNw+ucfJT2ZmpjIyMlxeAADg2uV2aJo0aZIqV66suLg4+fj4yMfHR3fccYeqVKmiiRMnFlhhKSkpkqTQ0FCX9tDQUGtbSkqKypcv77K9ZMmSCgkJcemT3xgXH+NSfXK352fUqFEKDAy0XlFRUe5OEQAAFCNu3z0XFBSkxYsXa/fu3dq1a5ckqVq1aqpSpUqBF+fJBg8erAEDBljvMzIyCE4AAFzDrug5TZJ000036aabbirIWlyEhYVJklJTUxUeHm61p6amqnbt2lafw4cPu+x3/vx5HTt2zNo/LCxMqampLn1y3/9Zn9zt+XE6nXI6nVcwMwAAUBzZCk0DBgzQyJEj5efn53J1JT9vvvlmgRQWExOjsLAwrVy50gpJGRkZ2rBhg5588klJUlxcnNLS0rRx40bVqVNHkrRq1Srl5OSofv36Vp8XX3xRWVlZKlWqlCRpxYoVio2NVXBwsNVn5cqV6t+/v3X8FStWKC4urkDmAgAAij9boemHH35QVlaW9f8vxeFwuHXwkydPas+ePdb7vXv3KikpSSEhIapYsaL69++vV155RTfddJNiYmI0ZMgQRUREqG3btpIufC3YvHlz9ejRQ1OnTlVWVpb69u2rjh07KiIiQpL0yCOPaPjw4erevbsGDRqkbdu2aeLEiRo/frx13KeeekpNmjTRG2+8oZYtW2rOnDn6/vvvXR5LAAAArnOFfi/fZaxevdpIyvPq0qWLMebCYweGDBliQkNDjdPpNE2bNjXJyckuYxw9etR06tTJ+Pv7m4CAANOtWzdz4sQJlz6bN282jRo1Mk6n00RGRprRo0fnqWXevHnm5ptvNt7e3qZGjRrm008/dWsuPHIAAIDix53Pb4cxxhRhZrtmZGRkKDAwUOnp6QoICCjqcgAAgA3ufH7b+nquXbt2tg/+8ccf2+4LAABQXNgKTYGBgYVdBwAAgEezFZqmTZtW2HUAAAB4tCt+TtORI0eUnJwsSYqNjdUNN9xQYEUBAAB4Grd/jcqpU6f097//XeHh4WrcuLEaN26siIgIde/eXadPny6MGgEAAIqc26FpwIABWrNmjT755BOlpaUpLS1Nixcv1po1a/TMM88URo0AAABFzu1HDpQrV04LFizQXXfd5dK+evVqdejQQUeOHCnI+ooNHjkAAEDx487nt9tXmk6fPq3Q0NA87eXLl+frOQAAcM1yOzTFxcVp2LBhOnv2rNV25swZDR8+nN/VBgAArllu3z03YcIENW/eXBUqVFCtWrUkSZs3b5aPj4+WL19e4AUCAAB4giv6NSqnT5/W7NmztWvXLkkXfnFu586d5evrW+AFFhesaQIAoPgp8F+jctttt2nlypUKDg7WiBEj9Oyzz6pHjx4FUiwAAEBxYGtN086dO3Xq1ClJ0vDhw3Xy5MlCLQoAAMDT2LrSVLt2bXXr1k2NGjWSMUbjxo2Tv79/vn2HDh1aoAUCAAB4AltrmpKTkzVs2DD99NNP2rRpk6pXr66SJfPmLYfDoU2bNhVKoZ6ONU0AABQ/7nx+u70Q3MvLSykpKSpfvvxfKvJaQ2gCAKD4KdSHW65evVohISF52s+fP6+1a9e6OxwAAECx4HZouueee3Ts2LE87enp6br77rsLpCgAAABP43ZoMsbI4XDkaT969Kj8/PwKpCgAAABPY/uJ4O3atZN0YbF3165d5XQ6rW3Z2dnasmWLGjZsWPAVAgAAeADboSkwMFDShStNZcqUcXn6t7e3txo0aMADLwEAwDXLdmiaNm2acm+0mzx58iWf0wQAAHAtcmtNkzFGs2fP1qFDhwqrHgAAAI/kVmjy8vLSTTfdpKNHjxZWPQAAAB7J7bvnRo8erYEDB2rbtm2FUQ8AAIBHcvuJ4MHBwTp9+rTOnz8vb29vlwXhkvJ9htP1gCeCAwBQ/Ljz+W17IXiuCRMmXGldAAAAxZbboalLly6FUQcAAIBHczs0SRceZrlo0SLt3LlTklSjRg21bt1aJUqUKNDiAAAAPIXboWnPnj267777dODAAcXGxkqSRo0apaioKH366aeqXLlygRcJAABQ1Ny+e65fv36qXLmy9u/fr02bNmnTpk3at2+fYmJi1K9fv8KoEQAAoMi5faVpzZo1Wr9+vUJCQqy2smXLavTo0brjjjsKtDgAAABP4faVJqfTqRMnTuRpP3nypLy9vQukKAAAAE/jdmhq1aqVevbsqQ0bNsgYI2OM1q9fr969e6t169aFUSMAAECRczs0TZo0SZUrV1ZcXJx8fHzk4+OjO+64Q1WqVNHEiRMLo0YAAIAi5/aapqCgIC1evFh79uyxHjlQrVo1ValSpcCLAwAA8BS2Q1NOTo7Gjh2rJUuW6Ny5c2ratKmGDRuW59eoAAAAXItsfz336quv6oUXXpC/v78iIyM1ceJE9enTpzBrAwAA8Bi2Q9P777+vKVOmaPny5Vq0aJE++eQTzZ49Wzk5OYVZHwAAgEewHZr27dun++67z3ofHx8vh8OhgwcPFkphAAAAnsR2aDp//rx8fHxc2kqVKqWsrKwCLwoAAMDT2F4IboxR165d5XQ6rbazZ8+qd+/e8vPzs9o+/vjjgq0QAADAA9gOTV26dMnT9uijjxZoMQAAAJ7KdmiaNm1aYdYBAADg0dx+IjgAAMD1iNAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA0eH5pOnDih/v37Kzo6Wr6+vmrYsKG+++47a/vJkyfVt29fVahQQb6+vqpevbqmTp3qMsbZs2fVp08flS1bVv7+/mrfvr1SU1Nd+uzbt08tW7ZU6dKlVb58eQ0cOFDnz5+/KnMEAACez+ND0xNPPKEVK1Zo5syZ2rp1q5o1a6b4+HgdOHBAkjRgwAB99tlnmjVrlnbu3Kn+/furb9++WrJkiTXG008/rU8++UTz58/XmjVrdPDgQbVr187anp2drZYtW+rcuXNat26dZsyYoenTp2vo0KFXfb4AAMBDGQ92+vRpU6JECbN06VKX9ttuu828+OKLxhhjatSoYUaMGHHJ7WlpaaZUqVJm/vz51vadO3caSSYxMdEYY8yyZcuMl5eXSUlJsfq8/fbbJiAgwGRmZtqqNT093Ugy6enp7k8UAAAUCXc+vz36StP58+eVnZ0tHx8fl3ZfX199/fXXkqSGDRtqyZIlOnDggIwxWr16tX788Uc1a9ZMkrRx40ZlZWUpPj7e2r9q1aqqWLGiEhMTJUmJiYmqWbOmQkNDrT4JCQnKyMjQ9u3b860tMzNTGRkZLi8AAHDt8ujQVKZMGcXFxWnkyJE6ePCgsrOzNWvWLCUmJurQoUOSpMmTJ6t69eqqUKGCvL291bx5c7311ltq3LixJCklJUXe3t4KCgpyGTs0NFQpKSlWn4sDU+723G35GTVqlAIDA61XVFRUQU4dAAB4GI8OTZI0c+ZMGWMUGRkpp9OpSZMmqVOnTvLyulD65MmTtX79ei1ZskQbN27UG2+8oT59+uiLL74o1LoGDx6s9PR067V///5CPR4AAChaJYu6gD9TuXJlrVmzRqdOnVJGRobCw8P18MMPq1KlSjpz5oxeeOEFLVy4UC1btpQk3XLLLUpKStK4ceMUHx+vsLAwnTt3TmlpaS5Xm1JTUxUWFiZJCgsL07fffuty3Ny763L7/JHT6ZTT6SyEGQMAAE/k8Veacvn5+Sk8PFzHjx/X8uXL1aZNG2VlZSkrK8u66pSrRIkSysnJkSTVqVNHpUqV0sqVK63tycnJ2rdvn+Li4iRJcXFx2rp1qw4fPmz1WbFihQICAlS9evWrMDsAAODpPP5K0/Lly2WMUWxsrPbs2aOBAweqatWq6tatm0qVKqUmTZpo4MCB8vX1VXR0tNasWaP3339fb775piQpMDBQ3bt314ABAxQSEqKAgAD985//VFxcnBo0aCBJatasmapXr67HHntMY8aMUUpKil566SX16dOHq0kAAEBSMQhN6enpGjx4sH777TeFhISoffv2evXVV1WqVClJ0pw5czR48GB17txZx44dU3R0tF599VX17t3bGmP8+PHy8vJS+/btlZmZqYSEBE2ZMsXaXqJECS1dulRPPvmk4uLi5Ofnpy5dumjEiBFXfb4AAMAzOYwxpqiLuBZkZGQoMDBQ6enpCggIKOpyAACADe58fhebNU0AAABFidAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2ODxoenEiRPq37+/oqOj5evrq4YNG+q7775z6bNz5061bt1agYGB8vPz0+233659+/ZZ28+ePas+ffqobNmy8vf3V/v27ZWamuoyxr59+9SyZUuVLl1a5cuX18CBA3X+/PmrMkcAAOD5PD40PfHEE1qxYoVmzpyprVu3qlmzZoqPj9eBAwckST/99JMaNWqkqlWr6ssvv9SWLVs0ZMgQ+fj4WGM8/fTT+uSTTzR//nytWbNGBw8eVLt27azt2dnZatmypc6dO6d169ZpxowZmj59uoYOHXrV5wsAADyTwxhjirqISzlz5ozKlCmjxYsXq2XLllZ7nTp11KJFC73yyivq2LGjSpUqpZkzZ+Y7Rnp6um644QZ98MEHevDBByVJu3btUrVq1ZSYmKgGDRrof//7n1q1aqWDBw8qNDRUkjR16lQNGjRIR44ckbe395/WmpGRocDAQKWnpysgIKAAZg8AAAqbO5/fHn2l6fz588rOzna5aiRJvr6++vrrr5WTk6NPP/1UN998sxISElS+fHnVr19fixYtsvpu3LhRWVlZio+Pt9qqVq2qihUrKjExUZKUmJiomjVrWoFJkhISEpSRkaHt27fnW1tmZqYyMjJcXgAA4Nrl0aGpTJkyiouL08iRI3Xw4EFlZ2dr1qxZSkxM1KFDh3T48GGdPHlSo0ePVvPmzfX555/rgQceULt27bRmzRpJUkpKiry9vRUUFOQydmhoqFJSUqw+Fwem3O252/IzatQoBQYGWq+oqKgCnj0AAPAkHh2aJGnmzJkyxigyMlJOp1OTJk1Sp06d5OXlpZycHElSmzZt9PTTT6t27dp6/vnn1apVK02dOrVQ6xo8eLDS09Ot1/79+wv1eAAAoGh5fGiqXLmy1qxZo5MnT2r//v369ttvlZWVpUqVKqlcuXIqWbKkqlev7rJPtWrVrLvnwsLCdO7cOaWlpbn0SU1NVVhYmNXnj3fT5b7P7fNHTqdTAQEBLi8AAHDt8vjQlMvPz0/h4eE6fvy4li9frjZt2sjb21u33367kpOTXfr++OOPio6OlnRh0XipUqW0cuVKa3tycrL27dunuLg4SVJcXJy2bt2qw4cPW31WrFihgICAPIEMAABcn0oWdQF/Zvny5TLGKDY2Vnv27NHAgQNVtWpVdevWTZI0cOBAPfzww2rcuLHuvvtuffbZZ/rkk0/05ZdfSpICAwPVvXt3DRgwQCEhIQoICNA///lPxcXFqUGDBpKkZs2aqXr16nrsscc0ZswYpaSk6KWXXlKfPn3kdDqLauoAAMCDeHxoSk9P1+DBg/Xbb78pJCRE7du316uvvqpSpUpJkh544AFNnTpVo0aNUr9+/RQbG6uPPvpIjRo1ssYYP368vLy81L59e2VmZiohIUFTpkyxtpcoUUJLly7Vk08+qbi4OPn5+alLly4aMWLEVZ8vAADwTB79nKbihOc0AQBQ/Fwzz2kCAADwFIQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2EJoAAABsIDQBAADYQGgCAACwgdAEAABgA6EJAADABkITAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAIAALCB0AQAAGADoQkAAMAGQhMAAIANhCYAAAAbCE0AAAA2lCzqAq4VxhhJUkZGRhFXAgAA7Mr93M79HL8cQlMBOXHihCQpKiqqiCsBAADuOnHihAIDAy/bx2HsRCv8qZycHB08eFBlypSRw+Eo6nKKXEZGhqKiorR//34FBAQUdTnXLM7z1cF5vjo4z1cP5/r/GGN04sQJRUREyMvr8quWuNJUQLy8vFShQoWiLsPjBAQEXPf/QV4NnOerg/N8dXCerx7O9QV/doUpFwvBAQAAbCA0AQAA2EBoQqFwOp0aNmyYnE5nUZdyTeM8Xx2c56uD83z1cK6vDAvBAQAAbOBKEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNOGKHDt2TJ07d1ZAQICCgoLUvXt3nTx58rL7nD17Vn369FHZsmXl7++v9u3bKzU1Nd++R48eVYUKFeRwOJSWllYIMygeCuM8b968WZ06dVJUVJR8fX1VrVo1TZw4sbCn4nHeeust3XjjjfLx8VH9+vX17bffXrb//PnzVbVqVfn4+KhmzZpatmyZy3ZjjIYOHarw8HD5+voqPj5eu3fvLswpFAsFeZ6zsrI0aNAg1axZU35+foqIiNDjjz+ugwcPFvY0PF5B/zxfrHfv3nI4HJowYUIBV10MGeAKNG/e3NSqVcusX7/efPXVV6ZKlSqmU6dOl92nd+/eJioqyqxcudJ8//33pkGDBqZhw4b59m3Tpo1p0aKFkWSOHz9eCDMoHgrjPP/nP/8x/fr1M19++aX56aefzMyZM42vr6+ZPHlyYU/HY8yZM8d4e3ub//73v2b79u2mR48eJigoyKSmpubb/5tvvjElSpQwY8aMMTt27DAvvfSSKVWqlNm6davVZ/To0SYwMNAsWrTIbN682bRu3drExMSYM2fOXK1peZyCPs9paWkmPj7ezJ071+zatcskJiaaevXqmTp16lzNaXmcwvh5zvXxxx+bWrVqmYiICDN+/PhCnonnIzTBbTt27DCSzHfffWe1/e9//zMOh8McOHAg333S0tJMqVKlzPz58622nTt3GkkmMTHRpe+UKVNMkyZNzMqVK6/r0FTY5/li//jHP8zdd99dcMV7uHr16pk+ffpY77Ozs01ERIQZNWpUvv07dOhgWrZs6dJWv35906tXL2OMMTk5OSYsLMyMHTvW2p6WlmacTqf58MMPC2EGxUNBn+f8fPvtt0aS+fXXXwum6GKosM7zb7/9ZiIjI822bdtMdHQ0ockYw9dzcFtiYqKCgoJUt25dqy0+Pl5eXl7asGFDvvts3LhRWVlZio+Pt9qqVq2qihUrKjEx0WrbsWOHRowYoffff/9Pf3Hita4wz/MfpaenKyQkpOCK92Dnzp3Txo0bXc6Rl5eX4uPjL3mOEhMTXfpLUkJCgtV/7969SklJcekTGBio+vXrX/a8X8sK4zznJz09XQ6HQ0FBQQVSd3FTWOc5JydHjz32mAYOHKgaNWoUTvHF0PX9qYQrkpKSovLly7u0lSxZUiEhIUpJSbnkPt7e3nn+YgsNDbX2yczMVKdOnTR27FhVrFixUGovTgrrPP/RunXrNHfuXPXs2bNA6vZ0v//+u7KzsxUaGurSfrlzlJKSctn+uf/rzpjXusI4z3909uxZDRo0SJ06dbpuf+lsYZ3n119/XSVLllS/fv0KvuhijNAEy/PPPy+Hw3HZ165duwrt+IMHD1a1atX06KOPFtoxPEFRn+eLbdu2TW3atNGwYcPUrFmzq3JMoCBkZWWpQ4cOMsbo7bffLupyrikbN27UxIkTNX36dDkcjqIux6OULOoC4DmeeeYZde3a9bJ9KlWqpLCwMB0+fNil/fz58zp27JjCwsLy3S8sLEznzp1TWlqay1WQ1NRUa59Vq1Zp69atWrBggaQLdyNJUrly5fTiiy9q+PDhVzgzz1LU5znXjh071LRpU/Xs2VMvvfTSFc2lOCpXrpxKlCiR587N/M5RrrCwsMv2z/3f1NRUhYeHu/SpXbt2AVZffBTGec6VG5h+/fVXrVq16rq9yiQVznn+6quvdPjwYZcr/tnZ2XrmmWc0YcIE/fLLLwU7ieKkqBdVofjJXaD8/fffW23Lly+3tUB5wYIFVtuuXbtcFijv2bPHbN261Xr997//NZLMunXrLnkXyLWssM6zMcZs27bNlC9f3gwcOLDwJuDB6tWrZ/r27Wu9z87ONpGRkZddONuqVSuXtri4uDwLwceNG2dtT09PZyF4AZ9nY4w5d+6cadu2ralRo4Y5fPhw4RRezBT0ef79999d/i7eunWriYiIMIMGDTK7du0qvIkUA4QmXJHmzZubW2+91WzYsMF8/fXX5qabbnK5Ff63334zsbGxZsOGDVZb7969TcWKFc2qVavM999/b+Li4kxcXNwlj7F69err+u45YwrnPG/dutXccMMN5tFHHzWHDh2yXtfTB9CcOXOM0+k006dPNzt27DA9e/Y0QUFBJiUlxRhjzGOPPWaef/55q/8333xjSpYsacaNG2d27txphg0blu8jB4KCgszixYvNli1bTJs2bXjkQAGf53PnzpnWrVubChUqmKSkJJef38zMzCKZoycojJ/nP+LuuQsITbgiR48eNZ06dTL+/v4mICDAdOvWzZw4ccLavnfvXiPJrF692mo7c+aM+cc//mGCg4NN6dKlzQMPPGAOHTp0yWMQmgrnPA8bNsxIyvOKjo6+ijMrepMnTzYVK1Y03t7epl69emb9+vXWtiZNmpguXbq49J83b565+eabjbe3t6lRo4b59NNPXbbn5OSYIUOGmNDQUON0Ok3Tpk1NcnLy1ZiKRyvI85z7857f6+L/Bq5HBf3z/EeEpgscxvz/hSMAAAC4JO6eAwAAsIHQBAAAYAOhCQAAwAZCEwAAgA2EJgAAABsITQAAADYQmgAAAGwgNAEAANhAaAJwzTty5IiefPJJVaxYUU6nU2FhYUpISNA333wjSXI4HFq0aFHRFgnA45Us6gIAoLC1b99e586d04wZM1SpUiWlpqZq5cqVOnr0aFGXBqAY4UoTgGtaWlqavvrqK73++uu6++67FR0drXr16mnw4MFq3bq1brzxRknSAw88IIfDYb2XpMWLF+u2226Tj4+PKlWqpOHDh+v8+fPWdofDobffflstWrSQr6+vKlWqpAULFljbz507p759+yo8PFw+Pj6Kjo7WqFGjrtbUARQwQhOAa5q/v7/8/f21aNEiZWZm5tn+3XffSZKmTZumQ4cOWe+/+uorPf7443rqqae0Y8cOvfPOO5o+fbpeffVVl/2HDBmi9u3ba/PmzercubM6duyonTt3SpImTZqkJUuWaN68eUpOTtbs2bNdQhmA4oVf2AvgmvfRRx+pR48eOnPmjG677TY1adJEHTt21C233CLpwhWjhQsXqm3bttY+8fHxatq0qQYPHmy1zZo1S88995wOHjxo7de7d2+9/fbbVp8GDRrotttu05QpU9SvXz9t375dX3zxhRwOx9WZLIBCw5UmANe89u3b6+DBg1qyZImaN2+uL7/8UrfddpumT59+yX02b96sESNGWFeq/P391aNHDx06dEinT5+2+sXFxbnsFxcXZ11p6tq1q5KSkhQbG6t+/frp888/L5T5Abg6CE0Args+Pj669957NWTIEK1bt05du3bVsGHDLtn/5MmTGj58uJKSkqzX1q1btXv3bvn4+Ng65m233aa9e/dq5MiROnPmjDp06KAHH3ywoKYE4CojNAG4LlWvXl2nTp2SJJUqVUrZ2dku22+77TYlJyerSpUqeV5eXv/3V+f69etd9lu/fr2qVatmvQ8ICNDDDz+s9957T3PnztVHH32kY8eOFeLMABQWHjkA4Jp29OhRPfTQQ/r73/+uW265RWXKlNH333+vMWPGqE2bNpKkG2+8UStXrtQdd9whp9Op4OBgDR06VK1atVLFihX14IMPysvLS5s3b9a2bdv0yiuvWOPPnz9fdevWVaNGjTR79mx9++23+s9//iNJevPNNxUeHq5bb71VXl5emj9/vsLCwhQUFFQUpwLAX0RoAnBN8/f3V/369TV+/Hj99NNPysrKUlRUlHr06KEXXnhBkvTGG29owIABeu+99xQZGalffvlFCQkJWrp0qUaMGKHXX39dpUqVUtWqVfXEE0+4jD98+HDNmTNH//jHPxQeHq4PP/xQ1atXlySVKVNGY8aM0e7du1WiRAndfvvtWrZsmcuVKgDFB3fPAcAVyu+uOwDXLv65AwAAYAOhCQAAwAbWNAHAFWJ1A3B94UoTAACADYQmAAAAGwhNAAAANhCaAAAAbCA0AQAA2EBoAgAAsIHQBAAAYAOhCQAAwAZCEwAAgA3/D7Jcpp4YcAFJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(DDPG_agent.env.portfolio_history[1:])\n",
    "print(DDPG_agent.env.portfolio_history)\n",
    "plt.title(\"Portfolio Change Over Time\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Portfolio value\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Convolution Lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
