{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  Last Price    Volume  SMAVG (15)\n",
      "2331 2023-03-07 20:00:00    0.596608  0.049707    0.072420\n",
      "2330 2023-03-07 20:30:00    0.606681  0.165330    0.086878\n",
      "2329 2023-03-08 14:30:00    0.634154  0.134774    0.099523\n",
      "2328 2023-03-08 15:00:00    0.608055  0.086473    0.077523\n",
      "2327 2023-03-08 15:30:00    0.571654  0.099766    0.067301\n",
      "...                  ...         ...       ...         ...\n",
      "473  2023-09-29 20:30:00    0.881409  0.306496    0.180971\n",
      "472  2023-10-02 14:30:00    0.794870  0.171930    0.194260\n",
      "471  2023-10-02 15:00:00    0.755034  0.144825    0.184963\n",
      "470  2023-10-02 15:30:00    0.762818  0.113712    0.166506\n",
      "469  2023-10-02 16:00:00    0.764192  0.092697    0.157100\n",
      "\n",
      "[1863 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import gymnasium\n",
    "from gymnasium import spaces\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Load data\n",
    "#C:\\Users\\rohit\\OneDrive\\Documents\\Asset-Pricing-with-Reinforcement-Learning\\XOM_30_minute_6_month_data.csv\n",
    "df = pd.read_csv('XOM_30_minute_6_month_data.csv', parse_dates=['Date'])\n",
    "df.sort_values('Date', inplace=True)\n",
    "\n",
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "df[['Last Price', 'Volume', 'SMAVG (15)']] = scaler.fit_transform(df[['Last Price', 'Volume', 'SMAVG (15)']])\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_df = df[:train_size]\n",
    "test_df = df[train_size:]\n",
    "\n",
    "print(train_df[10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPGTradingEnv(gymnasium.Env):\n",
    "\n",
    "  def __init__(self, df):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.df = df\n",
    "    self.current_step = 0\n",
    "    self.total_steps = len(df) - 1\n",
    "\n",
    "    # Negatives mean quantity to sell, 0 is hold, positives mean buy\n",
    "    self.action_space = spaces.Box(low=-1, high=1, shape=(1, ), dtype=np.float32)\n",
    "    # Observation space: normalized last price, normalized shares held, normalized cash balance\n",
    "    self.observation_space = spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32)\n",
    "\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    self.current_step = 0\n",
    "    self.total_profit = 0\n",
    "    self.initial_balance = 10000\n",
    "    self.cash_balance = self.initial_balance\n",
    "    self.shares_held = 0\n",
    "    self.portfolio_value = self.cash_balance\n",
    "\n",
    "    self.previous_portfolio_value = self.portfolio_value\n",
    "    # For plotting\n",
    "    self.portfolio_history = [self.portfolio_value]\n",
    "\n",
    "    return self.get_observation()\n",
    "\n",
    "  def get_observation(self):\n",
    "    current_price = self.df.loc[self.current_step, 'Last Price']\n",
    "    return np.array([current_price, self.shares_held, self.cash_balance])\n",
    "\n",
    "  # Action space is one number between -1 and 1.\n",
    "  def take_action(self, action_value):\n",
    "    current_price = self.df.loc[self.current_step, 'Last Price']\n",
    "    if action_value > 0:\n",
    "      self.buy_stock(action_value, current_price)\n",
    "    elif action_value < 0:\n",
    "      self.sell_stock(action_value, current_price)\n",
    "    # Update the portfolio value\n",
    "    self.previous_portfolio_value = self.portfolio_value\n",
    "    self.portfolio_value = self.cash_balance + (self.shares_held * current_price)\n",
    "\n",
    "  def buy_stock(self, num_stocks, current_price):\n",
    "    self.cash_balance -= (num_stocks * current_price)\n",
    "    self.shares_held += num_stocks\n",
    "\n",
    "  def sell_stock(self, num_stocks, current_price):\n",
    "    self.cash_balance += (num_stocks * current_price)\n",
    "    self.shares_held -= num_stocks\n",
    "\n",
    "  def step(self, action):\n",
    "    self.current_step += 1\n",
    "    self.take_action(action)\n",
    "    reward = self.calculate_reward()\n",
    "    terminated = (self.current_step >= self.total_steps)\n",
    "    observation = self.get_observation()\n",
    "    info = {'current_step': self.current_step, 'portfolio_value': self.portfolio_value}\n",
    "    self.portfolio_history.append(self.portfolio_value)\n",
    "    return observation, reward, terminated, info\n",
    "\n",
    "  def render(self, mode='human'):\n",
    "    if mode == 'human':\n",
    "      print(f\"Step: {self.current_step}, Portfolio Value: {self.portfolio_value}\")\n",
    "\n",
    "  # The reward is the change in portfolio value the next time_step\n",
    "  def calculate_reward(self):\n",
    "    reward = self.portfolio_value - self.previous_portfolio_value\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDPG Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor & Critic Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Current state\n",
    "# Output: Action to be taken\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=128):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "# Input: Current State & Actor's action\n",
    "# Output: Expected value of state-action pair\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=128):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1_state = nn.Linear(state_dim, 64)\n",
    "        self.fc2_state = nn.Linear(64, 64)\n",
    "        self.fc2_action = nn.Linear(action_dim, 64)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x_state = F.relu(self.fc1_state(state))\n",
    "        x_state = F.relu(self.fc2_state(x_state))\n",
    "\n",
    "        x_action = F.relu(self.fc2_action(action))\n",
    "\n",
    "        x = torch.cat((x_state, x_action), dim=0)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m action \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(action_dim)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Execute action ğ´, observe reward ğ‘… and next-state ğ‘†â€²\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m new_state, reward, terminated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Store transition (ğ‘†,ğ´,ğ‘…,ğ‘†â€²) in ğ·\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# transition = (state, action, reward, new_state)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m transition \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mFloatTensor(state), torch\u001b[38;5;241m.\u001b[39mFloatTensor(action), reward, torch\u001b[38;5;241m.\u001b[39mFloatTensor(new_state\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)))\n",
      "Cell \u001b[0;32mIn[29], line 59\u001b[0m, in \u001b[0;36mDDPGTradingEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     57\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_reward()\n\u001b[1;32m     58\u001b[0m terminated \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_steps)\n\u001b[0;32m---> 59\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_step\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportfolio_value\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio_value}\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio_history\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mportfolio_value)\n",
      "Cell \u001b[0;32mIn[29], line 33\u001b[0m, in \u001b[0;36mDDPGTradingEnv.get_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_observation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     32\u001b[0m   current_price \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Price\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_price\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshares_held\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcash_balance\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Because DDPG is an off-policy actor-critic policy-gradient algorithm, this means that the critic\n",
    "# evaluates the actor, but because they are off-policy, the agents act according to their own\n",
    "# policy but learn according to the target policy.\n",
    "\n",
    "# Initialise environment:\n",
    "env = DDPGTradingEnv(df)\n",
    "\n",
    "# Pseudocode line 1:\n",
    "# Initialize replay memory ğ· to capacity ğ‘\n",
    "N = 1000\n",
    "replay_memory = []\n",
    "# replay_memory = deque(maxlen=N)\n",
    "# Initialise minibatch size\n",
    "minibatch_size = 50\n",
    "    \n",
    "# Pseudocode line 2 & 3:\n",
    "# Initialize actor network ğœ‹Ì‚ 1 with parameters ğ’˜1 arbitrarily\n",
    "# Initialize target actor network ğœ‹Ì‚ 2 with parameters ğ’˜2=ğ’˜1\n",
    "state_dim = 3\n",
    "action_dim = 1\n",
    "actor_model = Actor(state_dim, action_dim)\n",
    "target_actor_model = Actor(state_dim, action_dim)\n",
    "\n",
    "# Pseudocode line 4 & 5:\n",
    "# Initialize critic network ğ‘Ì‚ 1 with parameters ğœ½1 arbitrarily\n",
    "# Initialize target critic network ğ‘Ì‚ 2 with parameters ğœ½2=ğœ½1\n",
    "critic_model = Critic(state_dim + action_dim, 1)\n",
    "target_critic_model = Critic(state_dim + action_dim, 1)\n",
    "\n",
    "# Pseudocode line 6: Algorithm parameters: target network learning rate ğ›½>0\n",
    "beta = 0.005\n",
    "# Gamma is the discount factor (importance of future rewards)\n",
    "gamma = 0.9\n",
    "\n",
    "# This is for the gradient descent, we will probably put this in a learn method in the DDPG class\n",
    "lr = 0.005\n",
    "optimizer_critic = optim.Adam(critic_model.parameters(), lr=lr)\n",
    "optimizer_actor = optim.Adam(actor_model.parameters(), lr=lr)\n",
    "\n",
    "# Loop for each episode:\n",
    "num_episodes = 100\n",
    "for i in range(num_episodes):\n",
    "    # Initialise random process Ïµ for action exploration\n",
    "    epsilon = 0.1\n",
    "    # Initialise S\n",
    "    state = env.reset()\n",
    "\n",
    "    # Loop for each step of episode (each time step in df)\n",
    "    terminated = False\n",
    "    while not terminated:\n",
    "        # Select action ğ´â†ğœ‹Ì‚ 1(ğ‘†,ğ’˜1)+îˆº\n",
    "        action = actor_model(torch.FloatTensor(state).to(device))\n",
    "        action = action.detach().to('cpu').numpy()\n",
    "        # Add exploration noise (optional)\n",
    "        action += epsilon * np.random.randn(action_dim)\n",
    "        # Execute action ğ´, observe reward ğ‘… and next-state ğ‘†â€²\n",
    "        new_state, reward, terminated, info = env.step(action)\n",
    "        # Store transition (ğ‘†,ğ´,ğ‘…,ğ‘†â€²) in ğ·\n",
    "        # transition = (state, action, reward, new_state)\n",
    "        transition = (torch.FloatTensor(state), torch.FloatTensor(action), reward, torch.FloatTensor(new_state.astype(np.float64)))\n",
    "        replay_memory.append(transition)\n",
    "        # For each transition (ğ‘†ğ‘—,ğ´ğ‘—,ğ‘…ğ‘—,ğ‘†â€²ğ‘—) in minibatch sampled from ğ·:\n",
    "        if len(replay_memory) <= minibatch_size:\n",
    "            minibatch_sampled_from_D = replay_memory\n",
    "        else:\n",
    "            minibatch_sampled_from_D = random.sample(replay_memory, minibatch_size)\n",
    "        for transition in minibatch_sampled_from_D:\n",
    "            # ğ‘¦â†ğ‘…ğ‘—+ğ›¾ğ‘Ì‚ 2(ğ‘†â€²ğ‘—,ğœ‹Ì‚ 2(ğ‘†â€²ğ‘—,ğ’˜2),ğœ½2)\n",
    "            state, action, reward, new_state = transition\n",
    "\n",
    "            # Makes sure state and action are on same device\n",
    "            state = state.to(device)\n",
    "            action = action.to(device)\n",
    "            new_state_tensor = torch.FloatTensor(new_state).to(device)\n",
    "\n",
    "            # ğœ‹Ì‚ 2(ğ‘†â€²ğ‘—,ğ’˜2)\n",
    "            target_actor_output = target_actor_model(new_state_tensor)\n",
    "            # y is the TD target value (improved Q-value)\n",
    "            y = reward + gamma * target_critic_model(new_state_tensor, target_actor_output)\n",
    "            \n",
    "            # Perform gradient descent step âˆ‡ğœ½1(ğ‘¦âˆ’ğ‘Ì‚ 1(ğ‘†ğ‘—,ğ´ğ‘—,ğœ½1))2 for critic (critic learning from target critic)\n",
    "            critic_output = critic_model(state, action)\n",
    "            # critic_loss = F.mse_loss(critic_output, y)\n",
    "            # y.detach removes tensor\n",
    "            critic_loss = nn.MSELoss().to(device)(critic_output, y.detach())\n",
    "            optimizer_critic.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            optimizer_critic.step()\n",
    "            # Perform gradient ascent step âˆ‡ğ‘¤1ğ¸[ğ‘Ì‚ 1(ğ‘†ğ‘—,ğœ‹Ì‚ 1(ğ‘†ğ‘—,ğ’˜1),ğœ½1)] for actor (actor learning from critic)\n",
    "            actor_output = actor_model(state)\n",
    "            actor_loss = -torch.mean(critic_model(state, actor_output))\n",
    "            optimizer_actor.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            optimizer_actor.step()\n",
    "        # Update target actor network parameters ğ’˜2â†ğ›½ğ’˜1+(1âˆ’ğ›½)ğ’˜2\n",
    "        for target_param, param in zip(target_actor_model.parameters(), actor_model.parameters()):\n",
    "            target_param.data.copy_(beta * param.data + (1 - beta) * target_param.data)    \n",
    "        # Update target critic network parameters ğœ½2â†ğ›½ğœ½1+(1âˆ’ğ›½)ğœ½2\n",
    "        for target_param, param in zip(target_critic_model.parameters(), critic_model.parameters()):\n",
    "            target_param.data.copy_(beta * param.data + (1 - beta) * target_param.data)\n",
    "\n",
    "        # Update state\n",
    "        state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the profit change\n",
    "plt.plot(env.portfolio_history)\n",
    "plt.title(\"Profit Change Over Time\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Total Profit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Convolution Lab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
